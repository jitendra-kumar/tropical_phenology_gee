{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.221\n",
      "0.6.13\n"
     ]
    }
   ],
   "source": [
    "print(ee.__version__)\n",
    "print(geemap.__version__)\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load Venus shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manaus_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_fgmanaus_footprint/venus_fgmanaus_footprint.shp'\n",
    "manaus = geemap.shp_to_ee(manaus_shp)\n",
    "info = manaus.geometry()\n",
    "manaus = ee.Geometry(info)\n",
    "\n",
    "atto_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_atto_footprint/venus_atto_footprint.shp'\n",
    "atto = geemap.shp_to_ee(atto_shp)\n",
    "info = atto.geometry()\n",
    "atto = ee.Geometry(info)\n",
    "\n",
    "corumba_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_corumba_footprint/venus_corumba_footprint.shp'\n",
    "corumba = geemap.shp_to_ee(corumba_shp)\n",
    "info = corumba.geometry()\n",
    "corumba = ee.Geometry(info)\n",
    "\n",
    "mato_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_mato_footprint/venus_mato_footprint.shp'\n",
    "mato = geemap.shp_to_ee(mato_shp)\n",
    "info = mato.geometry()\n",
    "mato = ee.Geometry(info)\n",
    "\n",
    "saop_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_saop_footprint/venus_saop_footprint.shp'\n",
    "saop = geemap.shp_to_ee(saop_shp)\n",
    "info = saop.geometry()\n",
    "saop = ee.Geometry(info)\n",
    "\n",
    "parana_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_parana_footprint/venus_parana_footprint.shp'\n",
    "parana = geemap.shp_to_ee(parana_shp)\n",
    "info = parana.geometry()\n",
    "parana = ee.Geometry(info)\n",
    "\n",
    "comodo_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_comodo_footprint/venus_comodo_footprint.shp'\n",
    "comodo = geemap.shp_to_ee(comodo_shp)\n",
    "info = comodo.geometry()\n",
    "comodo = ee.Geometry(info)\n",
    "\n",
    "k34_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_k34_footprint/venus_k34_footprint.shp'\n",
    "k34 = geemap.shp_to_ee(k34_shp)\n",
    "info = k34.geometry()\n",
    "k34 = ee.Geometry(info)\n",
    "\n",
    "jam_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_jam_footprint/venus_jam_footprint.shp'\n",
    "jam = geemap.shp_to_ee(jam_shp)\n",
    "info = jam.geometry()\n",
    "jam = ee.Geometry(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Load Rondonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Polygon', 'coordinates': [[[-64.72361622081152, -9.881468125314736], [-64.22954281454578, -9.881468125314736], [-64.22954281454578, -9.387394719048999], [-64.72361622081152, -9.387394719048999], [-64.72361622081152, -9.881468125314736]]]}\n"
     ]
    }
   ],
   "source": [
    "# Import grid\n",
    "sitename = 'rondonia'\n",
    "grid_shp = '/data/6ru/shapefiles/rondonia_test.shp'\n",
    "grid_fc = geemap.shp_to_ee(grid_shp)\n",
    "\n",
    "# Extract coordinates from feature collection\n",
    "grid_fc_dict = grid_fc.getInfo()\n",
    "feats = grid_fc_dict['features']\n",
    "coord_list = []\n",
    "for d in feats:\n",
    "    coords = d['geometry']['coordinates']\n",
    "    coord_list.append(coords)\n",
    "\n",
    "# Create polygons from coordinates\n",
    "polys = []\n",
    "for coord in coord_list:\n",
    "    poly = ee.Geometry.Polygon(coord)\n",
    "    polys.append(poly)\n",
    "\n",
    "# Select only the first 100 grid squares\n",
    "#idx = list(range(0,100))\n",
    "#polys = [ polys[i] for i in idx]\n",
    "\n",
    "# Select one of first 100 grid squares\n",
    "geom = polys[0]\n",
    "fc = ee.FeatureCollection(geom)\n",
    "print(geom.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Load boundaries #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "br = (ee.FeatureCollection(\"FAO/GAUL/2015/level1\")\n",
    "       .filterMetadata('ADM0_NAME', 'equals', 'Brazil')\n",
    "       .filterMetadata('ADM1_NAME', 'equals', 'Amazonas')\n",
    "      )\n",
    "\n",
    "# Create grid\n",
    "# https://developers.google.com/earth-engine/tutorials/community/drawing-tools\n",
    "def make_grid(region, a_scale):\n",
    "    \"\"\"\n",
    "    Creates a grid around a specified ROI.\n",
    "    User inputs their reasonably small ROI.\n",
    "    User inputs a scale where 100000 = 100km.\n",
    "    \"\"\"\n",
    "    # Creates image with 2 bands ('longitude', 'latitude') in degrees\n",
    "    lonLat = ee.Image.pixelLonLat()\n",
    "\n",
    "    # Select bands, multiply times big number, and truncate\n",
    "    lonGrid = (lonLat\n",
    "               .select('latitude')\n",
    "               .multiply(10000000)\n",
    "               .toInt()\n",
    "              )\n",
    "    latGrid = (lonLat\n",
    "              .select('longitude')\n",
    "              .multiply(10000000)\n",
    "              .toInt()\n",
    "              )\n",
    "\n",
    "    # Multiply lat and lon images and reduce to vectors\n",
    "    grid = (lonGrid\n",
    "            .multiply(latGrid)\n",
    "            .reduceToVectors(\n",
    "                geometry = region,\n",
    "                scale = a_scale, # 100km-sized boxes needs 100,000\n",
    "                geometryType = 'polygon')\n",
    "           )\n",
    "    \n",
    "    return(grid)\n",
    "\n",
    "# Make test grid (half degree squares)\n",
    "grid_55km = make_grid(br, 40000)\n",
    "\n",
    "# Access coordinates of grid squares\n",
    "grid_dict = grid_55km.getInfo()\n",
    "\n",
    "feats = grid_dict['features']\n",
    "coord_list = []\n",
    "for d in feats:\n",
    "    geom = d['geometry']\n",
    "    coords = geom['coordinates']\n",
    "    coord_list.append(coords)\n",
    "    \n",
    "# Create a list of several ee.Geometry.Polygons\n",
    "polys = []\n",
    "for coord in coord_list:\n",
    "    poly = ee.Geometry.Polygon(coord)\n",
    "    polys.append(poly)\n",
    "    \n",
    "# Make grid smaller if it's huge\n",
    "idx = [0]\n",
    "polys = [ polys[i] for i in idx]\n",
    "\n",
    "# Make the whole grid a feature collection for export purposes\n",
    "grid = ee.FeatureCollection(polys)\n",
    "grid_fc = grid\n",
    "fc = grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b7fedf58c94a1e8748870ab781a32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-2.3356235491202306, -56.59386289953019], controls=(WidgetControl(options=['position'], widget=HBo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = (ee.ImageCollection('COPERNICUS/S2')\n",
    "       .filterDate('2017-01-01', '2020-12-31')\n",
    "       .sort('CLOUDY_PIXEL_PERCENTAGE', False))\n",
    "\n",
    "col = col.map(lambda image: image.clip(grid_fc))\n",
    "\n",
    "Map = geemap.Map()\n",
    "Map.add_basemap(\"SATELLITE\")\n",
    "Map.addLayer(grid_fc, {}, 'grid')\n",
    "Map.addLayer(col, {'bands': ['B4', 'B3', 'B2'], 'min':0, 'max':3000}, 'col')\n",
    "Map.center_object(grid_fc, zoom=8)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDATE = '2017-01-01'\n",
    "EDATE = '2020-12-31'\n",
    "\n",
    "# Daily mean 2m air temperature\n",
    "era5_2mt = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                   .select('mean_2m_air_temperature')\n",
    "                   .filterBounds(fc)\n",
    "                   .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "#print(era5_2mt))\n",
    "\n",
    "# Daily total precipitation sums\n",
    "era5_tp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('total_precipitation')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "\n",
    "era5_2mt = era5_2mt.map(lambda img: img.clip(fc))\n",
    "era5_tp = era5_tp.map(lambda img: img.clip(fc))\n",
    "\n",
    "# Visualization palette for total precipitation\n",
    "visTp = {\n",
    "  'min': 0.00,\n",
    "  'max': 0.03,\n",
    "  'palette': ['#FFFFFF', '#00FFFF', '#0080FF', '#DA00FF', '#FFA400', '#FF0000']\n",
    "}\n",
    "\n",
    "# Visualization palette for temperature (mean, min and max) and 2m dewpoint\n",
    "# temperature\n",
    "vis2mt = {\n",
    "  'min': 297,\n",
    "  'max': 303,\n",
    "  'palette': [\n",
    "    '#000080', '#0000D9', '#4000FF', '#8000FF', '#0080FF', '#00FFFF', '#00FF80',\n",
    "    '#80FF00', '#DAFF00', '#FFFF00', '#FFF500', '#FFDA00', '#FFB000', '#FFA400',\n",
    "    '#FF4F00', '#FF2500', '#FF0A00', '#FF00FF'\n",
    "  ]\n",
    "}\n",
    "\n",
    "Map.addLayer(era5_2mt, vis2mt, 'air temp')\n",
    "Map.addLayer(era5_tp, visTp, 'precip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'ImageCollection', 'bands': [], 'features': [{'type': 'Image', 'bands': [{'id': 'mean_2m_air_temperature', 'data_type': {'type': 'PixelType', 'precision': 'float'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}], 'properties': {'step': [1, 2017], 'system:index': '0'}}]}\n"
     ]
    }
   ],
   "source": [
    "years = ee.List.sequence(2017, 2020)\n",
    "step = ee.List.sequence(1, 365, 15)\n",
    "\n",
    "clipped_cols = [era5_2mt, era5_tp]\n",
    "all_cols = []\n",
    "for a_col in clipped_cols:\n",
    "    def byYear(y):\n",
    "        y = ee.Number(y)\n",
    "        def byStep(d):\n",
    "            d = ee.Number(d)\n",
    "            return (a_col\n",
    "                    .filter(ee.Filter.calendarRange(y, y, 'year')) #yearly step\n",
    "                    .filter(ee.Filter.calendarRange(d, d.add(14), 'day_of_year')) #15-day step\n",
    "                    .mean()\n",
    "                    .set('step', [d, y])) #Add properties\n",
    "                \n",
    "        return step.map(byStep)\n",
    "\n",
    "    col = ee.ImageCollection.fromImages(years.map(byYear).flatten())\n",
    "    all_cols.append(col)\n",
    "    \n",
    "column = all_cols[0].filter(ee.Filter.eq('system:index', '0'))\n",
    "print(column.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am_all_0', 'am_all_1']\n"
     ]
    }
   ],
   "source": [
    "# Make a list of file names\n",
    "tiles = []\n",
    "sitename = 'am_all'\n",
    "for num in range(len(all_cols)):\n",
    "    index = str(sitename + '_{}'.format(num))\n",
    "    tiles.append(index)\n",
    "\n",
    "print(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 already exists. Skipping...\n",
      "Image 1 already exists. Skipping...\n",
      "Image 2 already exists. Skipping...\n",
      "Image 3 already exists. Skipping...\n",
      "Image 4 already exists. Skipping...\n",
      "Image 5 already exists. Skipping...\n",
      "Image 6 already exists. Skipping...\n",
      "Image 7 already exists. Skipping...\n",
      "Image 8 already exists. Skipping...\n",
      "Image 9 already exists. Skipping...\n",
      "Image 10 already exists. Skipping...\n",
      "Image 11 already exists. Skipping...\n",
      "Image 12 already exists. Skipping...\n",
      "Image 13 already exists. Skipping...\n",
      "Image 14 already exists. Skipping...\n",
      "Image 15 already exists. Skipping...\n",
      "Image 16 already exists. Skipping...\n",
      "Image 17 already exists. Skipping...\n",
      "Image 18 already exists. Skipping...\n",
      "Image 19 already exists. Skipping...\n",
      "Image 20 already exists. Skipping...\n",
      "Image 21 already exists. Skipping...\n",
      "Image 22 already exists. Skipping...\n",
      "Image 23 already exists. Skipping...\n",
      "Image 24 already exists. Skipping...\n",
      "Exporting Image 0\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/1778f815cba2efc6abe6a3cd6e698a6d-b01f94c08405ef210e875333386a7896:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/0.tif\n",
      "Time elapsed: 00:00:05.88\n",
      "Exporting Image 1\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/a94f01797c785ba4438d28bb30de30bc-07511aa7ae670fcd61b1499e392f7df5:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/1.tif\n",
      "Time elapsed: 00:00:06.17\n",
      "Exporting Image 2\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/b87da414fa63be15e360a88c6a432491-da6d57f9a6aef857828474d359ff71d9:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/2.tif\n",
      "Time elapsed: 00:00:06.44\n",
      "Exporting Image 3\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/025c241d9bd25f6baf76d7d9f2e79586-5a6308d6836ef6786d61fb221eeb9716:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/3.tif\n",
      "Time elapsed: 00:00:06.06\n",
      "Exporting Image 4\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/3e632edd2e510e3e9789d2abdbe7a0f1-ecc42a8e42117ea8315e58a9d8885727:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/4.tif\n",
      "Time elapsed: 00:00:05.81\n",
      "Exporting Image 5\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/cc363b63d9b87341ed607c3bc59f9735-a7504a62ebe18bc264625dc49d3a3732:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/5.tif\n",
      "Time elapsed: 00:00:05.25\n",
      "Exporting Image 6\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/1979bd6f55ea09e586ddc763b999fea1-7c1803c463a8d04e2a3048974debdfef:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/6.tif\n",
      "Time elapsed: 00:00:05.56\n",
      "Exporting Image 7\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/3ef51cc933ca07b31ff1ec7825738e97-b619ec0a15c8a04d653bdb9367c2faa3:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/7.tif\n",
      "Time elapsed: 00:00:06.01\n",
      "Exporting Image 8\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/6c0286199fed3a3f925f567fab461325-172ae6c201e56d310277c4c28b5043f3:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/8.tif\n",
      "Time elapsed: 00:00:06.69\n",
      "Exporting Image 9\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/42d672f485c1153c8dfce62fe57ced61-c2ce1fe6f6725253d85d46b7edf71b87:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/9.tif\n",
      "Time elapsed: 00:00:06.60\n",
      "Exporting Image 10\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/a8e0b1becd3277cdb9548f64b81ee787-17528b2c23de928e97b71622417a366a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/10.tif\n",
      "Time elapsed: 00:00:07.02\n",
      "Exporting Image 11\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/148172cc31220c2b2f425ea92db47a2e-b700e6e528cb538f31a18bd603c1f7e6:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/11.tif\n",
      "Time elapsed: 00:00:06.35\n",
      "Exporting Image 12\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/24241ca49725beccc6c1db47dd3e12ea-3a13af86c85275215a81fd9b10931812:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/12.tif\n",
      "Time elapsed: 00:00:06.87\n",
      "Exporting Image 13\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/81de328bba914f1055b94345bc11bc33-23023b9abbc484603b3390cc4031cf96:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/13.tif\n",
      "Time elapsed: 00:00:06.03\n",
      "Exporting Image 14\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/c7eb0359114fe45a7f47cc349806551e-ac558c6c04fb78276e8c456c8d73b01f:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/14.tif\n",
      "Time elapsed: 00:00:07.37\n",
      "Exporting Image 15\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/497f879ff7c435ac6fb3bf7e2aa46b8a-0ff06397e3e22553b656d2c6e8d26791:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/15.tif\n",
      "Time elapsed: 00:00:06.39\n",
      "Exporting Image 16\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/15de932990f60f2192a831cf13f7a4e1-5e7b31038ee9ce409a30939e7cd0c05a:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/16.tif\n",
      "Time elapsed: 00:00:06.19\n",
      "Exporting Image 17\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/3ad10b5ce2b93d75f2c2876ce2176ba8-ee8fdc16efb2d433d070b0d101827d04:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/17.tif\n",
      "Time elapsed: 00:00:05.88\n",
      "Exporting Image 18\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/a32a745cca130e2fb8805ea8e71f4c82-494b52461389aebba4b4b0142c6f5281:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/18.tif\n",
      "Time elapsed: 00:00:06.94\n",
      "Exporting Image 19\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/db23289a9ff7e5765d295f8276543aa3-5b37800e8a0dba00211e38093195fcd4:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/19.tif\n",
      "Time elapsed: 00:00:06.10\n",
      "Exporting Image 20\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/2446c67102cf9f05cc8df875ed576ed0-b5613380c57ee3084cd1a80c3c9ce744:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/20.tif\n",
      "Time elapsed: 00:00:07.90\n",
      "Exporting Image 21\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/807ccae9fb69934e5850ee4ec703064e-518d07db3e91d1cb823da32539d59b82:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/21.tif\n",
      "Time elapsed: 00:00:06.15\n",
      "Exporting Image 22\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/8186ccffd76c2d1226c2ed188234910e-2d552b8437348e5e9949e2d6a0296d90:getPixels\n",
      "Please wait ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/22.tif\n",
      "Time elapsed: 00:00:07.13\n",
      "Exporting Image 23\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/ea772e64e826d81b4a9a0ade58ff5faa-4a9a8cb44a36a940bf3e04d1258bb107:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/23.tif\n",
      "Time elapsed: 00:00:06.72\n",
      "Exporting Image 24\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/23f51d6c1b203e459756b2c55baece28-4b48f75bcc6030110602e32803443ca6:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to /Users/morgansteckler/Desktop/ro10_1_2018/24.tif\n",
      "Time elapsed: 00:00:02.81\n",
      "Total time elapsed: 00:02:48.61\n"
     ]
    }
   ],
   "source": [
    "# Export monthly images from a collection\n",
    "import os, time\n",
    "\n",
    "polys = [polys[0], polys[0]]\n",
    "tic1 = time.time()\n",
    "for a_col, a_tile, poly in zip(all_cols, tiles, polys):\n",
    "    ilist = a_col.toList(a_col.size())\n",
    "    for i in range(0,25):\n",
    "        if len(ee.Image(ilist.get(i)).bandNames().getInfo()) <= 0:\n",
    "            print(\"ERROR; No bands found in image index %d... will skip export.\"%(i))\n",
    "        else:\n",
    "            filename = \"/Users/morgansteckler/Desktop/{}/{}.tif\".format(a_tile,i)\n",
    "            temp_dir = \"/Users/morgansteckler/Desktop/{}/\".format(a_tile)\n",
    "            if not os.path.exists(temp_dir):\n",
    "                os.mkdir(temp_dir)\n",
    "            if os.path.exists(filename):\n",
    "                print(\"Image {} already exists. Skipping...\".format(i))\n",
    "                next\n",
    "            else:\n",
    "                tic = time.time()\n",
    "                print(\"Exporting Image %d\"%(i))\n",
    "                geemap.ee_export_image(ee.Image(ilist.get(i)), \n",
    "                                       filename=filename, \n",
    "                                       scale=30, \n",
    "                                       region=poly, \n",
    "                                       file_per_band=False)\n",
    "                toc = time.time()\n",
    "                hours, rem = divmod(toc-tic, 3600)\n",
    "                mins, secs = divmod(rem, 60)\n",
    "                print(\"Time elapsed: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "                      .format(int(hours),int(mins),secs))\n",
    "toc1 = time.time()\n",
    "hrs1, rem1 = divmod(toc1-tic1, 3600)\n",
    "mins1, secs1 = divmod(rem1,  60)\n",
    "print(\"Total time elapsed: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "      .format(int(hrs1),int(mins1),secs1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Roraima #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some processing routines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "\n",
    "RES=30\n",
    "\n",
    "def region_mean_Image(img):\n",
    "    # mean over all pixels in the region for the image\n",
    "    return img.set('mean', img.reduceRegion(ee.Reducer.mean(), geometry=geom, scale=RES)) \n",
    "\n",
    "\n",
    "def region_mean_ImageCollection(ic):\n",
    "    # mean over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_mean_Image)\n",
    "    stats_list = stats.aggregate_array('mean')\n",
    "    return np.array(stats_list.getInfo())\n",
    "\n",
    "# Median\n",
    "def region_median_Image(img):\n",
    "    # mean over all pixels in the region for the image\n",
    "    return img.set('median', img.reduceRegion(ee.Reducer.median(), geometry=geom, scale=RES)) \n",
    "\n",
    "def region_median_ImageCollection(ic):\n",
    "    # mean over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_median_Image)\n",
    "    stats_list = stats.aggregate_array('median')\n",
    "    return np.array(stats_list.getInfo())\n",
    "\n",
    "# Stddev\n",
    "def region_stddev_Image(img):\n",
    "    # stddev over all pixels in the region for the image\n",
    "    return img.set('stddev', img.reduceRegion(ee.Reducer.stdDev(), geometry=geom, scale=RES)) \n",
    "\n",
    "def region_stddev_ImageCollection(ic):\n",
    "    # stddev over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_stddev_Image)\n",
    "    stats_list = stats.aggregate_array('stddev')\n",
    "    return np.array(stats_list.getInfo())\n",
    "\n",
    "# Percentiles\n",
    "def region_percentiles_Image(img):\n",
    "    # 5,10,25,75,90,95 percentiles over all pixels in the region for the image\n",
    "    return img.set('percentiles', img.reduceRegion(ee.Reducer.percentile([5,10,25,75,90,95]), geometry=fc, scale=20)) #) mean, median, stdDev, percentiles\n",
    "\n",
    "def region_percentiles_ImageCollection(ic):\n",
    "    # percentiles over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_percentiles_Image)\n",
    "    stats_list = stats.aggregate_array('percentiles')\n",
    "    return np.array(stats_list.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append ndre percentile dict values to new lists\n",
    "def p_list(alist, varname):\n",
    "    p10, p25, p5, p75, p90, p95 = [], [], [], [], [], []\n",
    "    for value in alist:\n",
    "        p5.append(value[varname+'_p5'])\n",
    "        p10.append(value[varname+'_p10'])\n",
    "        p25.append(value[varname+'_p25'])\n",
    "        p75.append(value[varname+'_p75'])\n",
    "        p90.append(value[varname+'_p90'])\n",
    "        p95.append(value[varname+'_p95'])\n",
    "    return p5, p10, p25, p75, p90, p95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of dates from ImageCollection\n",
    "def ymdList(imgcol):\n",
    "    def iter_func(image, newlist):\n",
    "        date = ee.Number.parse(image.date().format(\"YYYYMMdd\"));\n",
    "        newlist = ee.List(newlist);\n",
    "        return ee.List(newlist.add(date).sort())\n",
    "    ymd = imgcol.iterate(iter_func, ee.List([]))\n",
    "    return list(ee.List(ymd).reduce(ee.Reducer.frequencyHistogram()).getInfo().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only the ndre mean, med, stddev dict values and append to new list\n",
    "def newList(alist, varname):\n",
    "    list_name = []\n",
    "    for value in alist:\n",
    "        list_name.append(value[varname])\n",
    "    return list_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ########################################\n",
    "## ERA5\n",
    "# ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ERA5 data \n",
    "# https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY\n",
    "\n",
    "SDATE = '2017-01-01'\n",
    "EDATE = '2020-12-31'\n",
    "\n",
    "# Daily mean 2m air temperature\n",
    "era5_2mt = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                   .select('mean_2m_air_temperature')\n",
    "                   .filterBounds(fc)\n",
    "                   .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "#print(era5_2mt))\n",
    "\n",
    "# Daily total precipitation sums\n",
    "era5_tp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('total_precipitation')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "\n",
    "# Daily mean 2m dewpoint temperature\n",
    "era5_2d = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('dewpoint_2m_temperature')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "\n",
    "# Daily mean sea-level pressure\n",
    "era5_mslp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                    .select('mean_sea_level_pressure')\n",
    "                    .filterBounds(fc)\n",
    "                    .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "# Convert pressure levels from Pa to hPa - Example for surface pressure\n",
    "def era5_sp(image):\n",
    "    return image.divide(100).set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "# Daily mean surface pressure\n",
    "era5_sp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('surface_pressure')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE))).map(era5_sp)\n",
    "\n",
    "\n",
    "# Daily mean 10m u-component of wind\n",
    "era5_u_wind_10m = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                          .select('u_component_of_wind_10m')\n",
    "                          .filterBounds(fc)\n",
    "                          .filter(ee.Filter.date(SDATE, EDATE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization palette for total precipitation\n",
    "visTp = {\n",
    "  'min': 0,\n",
    "  'max': 0.1,\n",
    "  'palette': ['#FFFFFF', '#00FFFF', '#0080FF', '#DA00FF', '#FFA400', '#FF0000']\n",
    "}\n",
    "\n",
    "# Visualization palette for temperature (mean, min and max) and 2m dewpoint\n",
    "# temperature\n",
    "vis2mt = {\n",
    "  'min': 250,\n",
    "  'max': 320,\n",
    "  'palette': [\n",
    "    '#000080', '#0000D9', '#4000FF', '#8000FF', '#0080FF', '#00FFFF', '#00FF80',\n",
    "    '#80FF00', '#DAFF00', '#FFFF00', '#FFF500', '#FFDA00', '#FFB000', '#FFA400',\n",
    "    '#FF4F00', '#FF2500', '#FF0A00', '#FF00FF'\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Visualization palette for u- and v-component of 10m wind\n",
    "visWind = {\n",
    "  'min': 0,\n",
    "  'max': 30,\n",
    "  'palette': [\n",
    "    '#FFFFFF', '#FFFF71', '#DEFF00', '#9EFF00', '#77B038', '#007E55', '#005F51',\n",
    "    '#004B51', '#013A7B', '#023AAD'\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Visualization palette for pressure (surface pressure, mean sea level\n",
    "# pressure) - adjust min and max values for mslp to min:990 and max:1050\n",
    "visPressure = {\n",
    "  'min': 500,\n",
    "  'max': 1150,\n",
    "  'palette': [\n",
    "    '#01FFFF', '#058BFF', '#0600FF', '#DF00FF', '#FF00FF', '#FF8C00', '#FF8C00'\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e173dbb7b544e8eadb644fdb0ebd9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-4.158708756590903, -64.70498486280152], controls=(WidgetControl(options=['position'], widget=HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map()\n",
    "Map.center_object(grid, zoom=10)\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_2mt = era5_2mt.map(lambda img: img.clip(grid_fc))\n",
    "Map.addLayer(era5_2mt, vis2mt, 'Daily mean 2m air temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp_percentile_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total precipitation\n",
    "# get area statistics\n",
    "tp_mean_list = region_mean_ImageCollection(era5_tp)\n",
    "tp_median_list = region_median_ImageCollection(era5_tp)\n",
    "tp_stddev_list = region_stddev_ImageCollection(era5_tp)\n",
    "#tp_percentile_list = region_percentiles_ImageCollection(era5_tp)\n",
    "\n",
    "# turn it into numpy array\n",
    "tp_mean = newList(tp_mean_list, 'total_precipitation')\n",
    "tp_median = newList(tp_median_list, 'total_precipitation')\n",
    "tp_stddev = newList(tp_stddev_list, 'total_precipitation')\n",
    "#tp_percentile = p_list(tp_percentile_list, 'total_precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2m air temperature\n",
    "# get area statistics\n",
    "t2m_mean_list = region_mean_ImageCollection(era5_2mt)\n",
    "t2m_median_list = region_median_ImageCollection(era5_2mt)\n",
    "t2m_stddev_list = region_stddev_ImageCollection(era5_2mt)\n",
    "#t2m_percentile_list = region_percentiles_ImageCollection(era5_2mt)\n",
    "\n",
    "# turn it into numpy array\n",
    "t2m_mean = newList(t2m_mean_list, 'mean_2m_air_temperature')\n",
    "t2m_median = newList(t2m_median_list, 'mean_2m_air_temperature')\n",
    "t2m_stddev = newList(t2m_stddev_list, 'mean_2m_air_temperature')\n",
    "#t2m_percentile = p_list(t2m_percentile_list, 'mean_2m_air_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5dates = ymdList(era5_tp)\n",
    "x = range(len(t2m_mean))\n",
    "plus_error = [x + y for x,y in zip(t2m_mean, t2m_stddev)]\n",
    "minus_error = [x - y for x,y in zip(t2m_mean, t2m_stddev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x,t2m_mean, color='blue', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mean and stddev to file\n",
    "sitename=\"am_0\"\n",
    "site_era5 = pd.DataFrame()\n",
    "site_era5['dates'] = era5dates\n",
    "site_era5['precip_mean'] = tp_mean\n",
    "site_era5['precip_stddev'] = tp_stddev\n",
    "site_era5['t2m_mean'] = t2m_mean\n",
    "site_era5['t2_stddev'] = t2m_stddev\n",
    "\n",
    "filename = \"/Users/morgansteckler/Desktop/%s_era5.daily\"%(sitename)\n",
    "site_era5.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ########################################\n",
    "## GLDAS 2.1\n",
    "# ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLDAS Net Longwave Radiation\n",
    "gldas21_net_longwave_radiation = (ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n",
    "                          .select('Lwnet_tavg')\n",
    "                          .filterBounds(fc)\n",
    "                          .filter(ee.Filter.date('2017-01-01', '2020-12-31')))\n",
    "\n",
    "# GLDAS Net Shortwave Radiation\n",
    "gldas21_net_shortwave_radiation = (ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n",
    "                          .select('Swnet_tavg')\n",
    "                          .filterBounds(fc)\n",
    "                          .filter(ee.Filter.date('2017-01-01', '2020-12-31')))\n",
    "\n",
    "#print(gldas21_net_longwave_radiation.size())\n",
    "#print(gldas21_net_shortwave_radiation.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 hourly to daily time series -- take mean of values within the day\n",
    "#1-day step\n",
    "years = ee.List.sequence(2017, 2020)\n",
    "period = ee.List.sequence(1, 30, 1)\n",
    "\n",
    "\n",
    "def byYear(y):\n",
    "    y = ee.Number(y)\n",
    "    def dailymean(startDoy):\n",
    "        startDoy = ee.Number(startDoy)\n",
    "        return (gldas21_net_longwave_radiation\n",
    "                .filter(ee.Filter.calendarRange(y, y, 'year'))\n",
    "                .filter(ee.Filter.calendarRange(startDoy, startDoy, 'day_of_year'))\n",
    "                .median())\n",
    "    return period.map(dailymean)\n",
    "\n",
    "mapped_doy = years.map(byYear).flatten()\n",
    "gldas21_net_longwave_radiation = ee.ImageCollection.fromImages(mapped_doy)\n",
    "\n",
    "\n",
    "def byYear(y):\n",
    "    y = ee.Number(y)\n",
    "    def dailymean(startDoy):\n",
    "        startDoy = ee.Number(startDoy)\n",
    "        return (gldas21_net_shortwave_radiation\n",
    "                .filter(ee.Filter.calendarRange(y, y, 'year'))\n",
    "                .filter(ee.Filter.calendarRange(startDoy, startDoy, 'day_of_year'))\n",
    "                .median())\n",
    "    return period.map(dailymean)\n",
    "\n",
    "mapped_doy = years.map(byYear).flatten()\n",
    "gldas21_net_shortwave_radiation = ee.ImageCollection.fromImages(mapped_doy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net longwave radiation\n",
    "# get area statistics\n",
    "nlwr_mean_list = region_mean_ImageCollection(gldas21_net_longwave_radiation)\n",
    "nlwr_median_list = region_median_ImageCollection(gldas21_net_longwave_radiation)\n",
    "nlwr_stddev_list = region_stddev_ImageCollection(gldas21_net_longwave_radiation)\n",
    "nlwr_percentile_list = region_percentiles_ImageCollection(gldas21_net_longwave_radiation)\n",
    "\n",
    "# turn it into numpy array\n",
    "nlwr_mean = newList(nlwr_mean_list, 'Lwnet_tavg')\n",
    "nlwr_median = newList(nlwr_median_list, 'Lwnet_tavg')\n",
    "nlwr_stddev = newList(nlwr_stddev_list, 'Lwnet_tavg')\n",
    "nlwr_percentile = p_list(nlwr_percentile_list, 'Lwnet_tavg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net shortwave radiation\n",
    "# get area statistics\n",
    "nswr_mean_list = region_mean_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "nswr_median_list = region_median_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "nswr_stddev_list = region_stddev_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "nswr_percentile_list = region_percentiles_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "\n",
    "# turn it into numpy array\n",
    "nswr_mean = newList(nswr_mean_list, 'Swnet_tavg')\n",
    "nswr_median = newList(nswr_median_list, 'Swnet_tavg')\n",
    "nswr_stddev = newList(nswr_stddev_list, 'Swnet_tavg')\n",
    "nswr_percentile = p_list(nswr_percentile_list, 'Swnet_tavg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export GLDAS2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mean and stddev to file\n",
    "site_gldas21 = pd.DataFrame()\n",
    "\n",
    "site_gldas21['nlwrad_mean'] = nlwr_mean\n",
    "site_gldas21['nlwrad_stddev'] = nlwr_stddev\n",
    "site_gldas21['nswrad_mean'] = nswr_mean\n",
    "site_gldas21['nswrad_stddev'] = nswr_stddev\n",
    "\n",
    "filename = \"/home/jbk/projects/climate/tropics/sentinel-2/data/gldas21/%s_gldas21.daily\"%(sitename)\n",
    "site_gldas21.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make few plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make lists with +/- SD\n",
    "plus_error = [x + y for x,y in zip(tp_mean, tp_stddev)]\n",
    "minus_error = [x - y for x,y in zip(tp_mean, tp_stddev)]\n",
    "\n",
    "plt.axes([2, 0, 2, 1])\n",
    "plt.grid(b = True, which = 'major', axis = 'x')\n",
    "plt.fill_between(icdates, plus_error, minus_error, color = \"grey\", alpha = .5, label = \"Standard Deviation\")\n",
    "plt.plot(icdates, tp_mean, label='tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_stddev(var_mean, var_stddev, var_name):\n",
    "    #Make lists with +/- SD\n",
    "    icdates=np.array(list(range(0,30)))\n",
    "    plus_error = [x + y for x,y in zip(var_mean, var_stddev)]\n",
    "    minus_error = [x - y for x,y in zip(var_mean, var_stddev)]\n",
    "\n",
    "    plt.axes([2, 0, 2, 1])\n",
    "    plt.grid(b = True, which = 'major', axis = 'x')\n",
    "    plt.fill_between(icdates, plus_error, minus_error, color = \"grey\", alpha = .5, label = \"Standard Deviation\")\n",
    "    plt.plot(icdates, var_mean, label=var_name)\n",
    "    plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(tp_mean, tp_stddev, var_name=\"Total Precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(t2m_mean, t2m_stddev, var_name=\"2m Air Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(nlwr_mean, nlwr_stddev, var_name=\"Net Long Wave Radiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(nlwr_mean, nlwr_stddev, var_name=\"Net Short Wave Radiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mean and stddev to file\n",
    "edata = np.column_stack((icdates, tp_mean, tp_stddev, t2m_mean, t2m_stddev))\n",
    "site_era5 = pd.DataFrame()\n",
    "site_era5['dates'] = icdates\n",
    "site_era5['precip_mean'] = tp_mean\n",
    "site_era5['precip_stddev'] = tp_stddev\n",
    "site_era5['t2m_mean'] = t2m_mean\n",
    "site_era5['t2_stddev'] = t2m_stddev\n",
    "site_era5['nlwrad_mean'] = nlwr_mean\n",
    "site_era5['nlwrad_stddev'] = nlwr_stddev\n",
    "site_era5['nswrad_mean'] = nswr_mean\n",
    "site_era5['nswrad_stddev'] = nswr_stddev\n",
    "\n",
    "site_era5.to_csv('manaus_era5.daily', index=False)\n",
    "#site_era5.to_csv('atto_era5.daily', index=False)\n",
    "#site_era5.to_csv('corumba_era5.daily', index=False)\n",
    "#site_era5.to_csv('mato_era5.daily', index=False)\n",
    "#site_era5.to_csv('saop_era5.daily', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate variables for Growing Degree Days calculation \n",
    "start_date = ee.Date('2016-01-01', 'UTC')\n",
    "def maccum_byYear(y):\n",
    "    def maccum_byMonth(m):\n",
    "        return (ic\n",
    "                .filter(ee.Filter.calendarRange(y, y, 'year'))\n",
    "                .filter(ee.Filter.calendarRage(m, m, 'month'))\n",
    "                .\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = ee.Date('2016-01-01', 'UTC')\n",
    "new_date = start_date.advance(2, 'month')\n",
    "#print(start_date)\n",
    "print(start_date, new_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ee.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gldasdates = ymdList(gldas21_net_longwave_radiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gldasdates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
