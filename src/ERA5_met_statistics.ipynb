{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.249\n",
      "0.8.8\n"
     ]
    }
   ],
   "source": [
    "print(ee.__version__)\n",
    "print(geemap.__version__)\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load shape files as regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manaus_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_fgmanaus_footprint/venus_fgmanaus_footprint.shp'\n",
    "manaus = geemap.shp_to_ee(manaus_shp)\n",
    "info = manaus.geometry()\n",
    "manaus = ee.Geometry(info)\n",
    "\n",
    "atto_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_atto_footprint/venus_atto_footprint.shp'\n",
    "atto = geemap.shp_to_ee(atto_shp)\n",
    "info = atto.geometry()\n",
    "atto = ee.Geometry(info)\n",
    "\n",
    "corumba_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_corumba_footprint/venus_corumba_footprint.shp'\n",
    "corumba = geemap.shp_to_ee(corumba_shp)\n",
    "info = corumba.geometry()\n",
    "corumba = ee.Geometry(info)\n",
    "\n",
    "mato_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_mato_footprint/venus_mato_footprint.shp'\n",
    "mato = geemap.shp_to_ee(mato_shp)\n",
    "info = mato.geometry()\n",
    "mato = ee.Geometry(info)\n",
    "\n",
    "saop_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_saop_footprint/venus_saop_footprint.shp'\n",
    "saop = geemap.shp_to_ee(saop_shp)\n",
    "info = saop.geometry()\n",
    "saop = ee.Geometry(info)\n",
    "\n",
    "parana_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_parana_footprint/venus_parana_footprint.shp'\n",
    "parana = geemap.shp_to_ee(parana_shp)\n",
    "info = parana.geometry()\n",
    "parana = ee.Geometry(info)\n",
    "\n",
    "comodo_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_comodo_footprint/venus_comodo_footprint.shp'\n",
    "comodo = geemap.shp_to_ee(comodo_shp)\n",
    "info = comodo.geometry()\n",
    "comodo = ee.Geometry(info)\n",
    "\n",
    "k34_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_k34_footprint/venus_k34_footprint.shp'\n",
    "k34 = geemap.shp_to_ee(k34_shp)\n",
    "info = k34.geometry()\n",
    "k34 = ee.Geometry(info)\n",
    "\n",
    "jam_shp = '/home/jbk/projects/climate/tropics/venus/footprints/venus_jam_footprint/venus_jam_footprint.shp'\n",
    "jam = geemap.shp_to_ee(jam_shp)\n",
    "info = jam.geometry()\n",
    "jam = ee.Geometry(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import grid\n",
    "sitename = \n",
    "grid_shp = '/data/6ru/amazonas_grid.shp'\n",
    "grid_fc = geemap.shp_to_ee(grid_shp)\n",
    "\n",
    "# Extract coordinates from feature collection\n",
    "grid_fc_dict = grid_fc.getInfo()\n",
    "feats = grid_fc_dict['features']\n",
    "coord_list = []\n",
    "for d in feats:\n",
    "    coords = d['geometry']['coordinates']\n",
    "    coord_list.append(coords)\n",
    "\n",
    "# Create polygons from coordinates\n",
    "polys = []\n",
    "for coord in coord_list:\n",
    "    poly = ee.Geometry.Polygon(coord)\n",
    "    polys.append(poly)\n",
    "\n",
    "# Select only the first 100 grid squares\n",
    "idx = list(range(0,100))\n",
    "polys = [ polys[i] for i in idx]\n",
    "\n",
    "# Select one of first 100 grid squares\n",
    "geom = polys[0]\n",
    "fc = ee.FeatureCollection(geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some processing routines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean\n",
    "def region_mean_Image(img):\n",
    "    # mean over all pixels in the region for the image\n",
    "    return img.set('mean', img.reduceRegion(ee.Reducer.mean(), geometry=geom, scale=20)) \n",
    "\n",
    "\n",
    "def region_mean_ImageCollection(ic):\n",
    "    # mean over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_mean_Image)\n",
    "    stats_list = stats.aggregate_array('mean')\n",
    "    return np.array(stats_list.getInfo())\n",
    "\n",
    "# Median\n",
    "def region_median_Image(img):\n",
    "    # mean over all pixels in the region for the image\n",
    "    return img.set('median', img.reduceRegion(ee.Reducer.median(), geometry=geom, scale=20)) \n",
    "\n",
    "def region_median_ImageCollection(ic):\n",
    "    # mean over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_median_Image)\n",
    "    stats_list = stats.aggregate_array('median')\n",
    "    return np.array(stats_list.getInfo())\n",
    "\n",
    "# Stddev\n",
    "def region_stddev_Image(img):\n",
    "    # stddev over all pixels in the region for the image\n",
    "    return img.set('stddev', img.reduceRegion(ee.Reducer.stdDev(), geometry=geom, scale=20)) \n",
    "\n",
    "def region_stddev_ImageCollection(ic):\n",
    "    # stddev over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_stddev_Image)\n",
    "    stats_list = stats.aggregate_array('stddev')\n",
    "    return np.array(stats_list.getInfo())\n",
    "\n",
    "# Percentiles\n",
    "def region_percentiles_Image(img):\n",
    "    # 5,10,25,75,90,95 percentiles over all pixels in the region for the image\n",
    "    return img.set('percentiles', img.reduceRegion(ee.Reducer.percentile([5,10,25,75,90,95]), geometry=fc, scale=20)) #) mean, median, stdDev, percentiles\n",
    "\n",
    "def region_percentiles_ImageCollection(ic):\n",
    "    # percentiles over all pixels in the region, for each image in the ImageCollection\n",
    "    stats = ic.map(region_percentiles_Image)\n",
    "    stats_list = stats.aggregate_array('percentiles')\n",
    "    return np.array(stats_list.getInfo())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append ndre percentile dict values to new lists\n",
    "def p_list(alist, varname):\n",
    "    p10, p25, p5, p75, p90, p95 = [], [], [], [], [], []\n",
    "    for value in alist:\n",
    "        p5.append(value[varname+'_p5'])\n",
    "        p10.append(value[varname+'_p10'])\n",
    "        p25.append(value[varname+'_p25'])\n",
    "        p75.append(value[varname+'_p75'])\n",
    "        p90.append(value[varname+'_p90'])\n",
    "        p95.append(value[varname+'_p95'])\n",
    "    return p5, p10, p25, p75, p90, p95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of dates from ImageCollection\n",
    "def ymdList(imgcol):\n",
    "    def iter_func(image, newlist):\n",
    "        date = ee.Number.parse(image.date().format(\"YYYYMMdd\"));\n",
    "        newlist = ee.List(newlist);\n",
    "        return ee.List(newlist.add(date).sort())\n",
    "    ymd = imgcol.iterate(iter_func, ee.List([]))\n",
    "    return list(ee.List(ymd).reduce(ee.Reducer.frequencyHistogram()).getInfo().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take only the ndre mean, med, stddev dict values and append to new list\n",
    "def newList(alist, varname):\n",
    "    list_name = []\n",
    "    for value in alist:\n",
    "        list_name.append(value[varname])\n",
    "    return list_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ########################################\n",
    "## ERA5\n",
    "# ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the ERA5 data \n",
    "# https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_DAILY\n",
    "\n",
    "SDATE = '2017-01-01'\n",
    "EDATE = '2020-07-09'\n",
    "\n",
    "# Daily mean 2m air temperature\n",
    "era5_2mt = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                   .select('mean_2m_air_temperature')\n",
    "                   .filterBounds(fc)\n",
    "                   .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "#print(era5_2mt))\n",
    "\n",
    "# Daily total precipitation sums\n",
    "era5_tp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('total_precipitation')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "\n",
    "# Daily mean 2m dewpoint temperature\n",
    "era5_2d = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('dewpoint_2m_temperature')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "\n",
    "# Daily mean sea-level pressure\n",
    "era5_mslp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                    .select('mean_sea_level_pressure')\n",
    "                    .filterBounds(fc)\n",
    "                    .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "# Convert pressure levels from Pa to hPa - Example for surface pressure\n",
    "def era5_sp(image):\n",
    "    return image.divide(100).set('system:time_start', image.get('system:time_start'))\n",
    "\n",
    "# Daily mean surface pressure\n",
    "era5_sp = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                  .select('surface_pressure')\n",
    "                  .filterBounds(fc)\n",
    "                  .filter(ee.Filter.date(SDATE, EDATE))).map(era5_sp)\n",
    "\n",
    "\n",
    "# Daily mean 10m u-component of wind\n",
    "era5_u_wind_10m = (ee.ImageCollection('ECMWF/ERA5/DAILY')\n",
    "                          .select('u_component_of_wind_10m')\n",
    "                          .filterBounds(fc)\n",
    "                          .filter(ee.Filter.date(SDATE, EDATE)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization palette for total precipitation\n",
    "visTp = {\n",
    "  'min': 0,\n",
    "  'max': 0.1,\n",
    "  'palette': ['#FFFFFF', '#00FFFF', '#0080FF', '#DA00FF', '#FFA400', '#FF0000']\n",
    "}\n",
    "\n",
    "# Visualization palette for temperature (mean, min and max) and 2m dewpoint\n",
    "# temperature\n",
    "vis2mt = {\n",
    "  'min': 250,\n",
    "  'max': 320,\n",
    "  'palette': [\n",
    "    '#000080', '#0000D9', '#4000FF', '#8000FF', '#0080FF', '#00FFFF', '#00FF80',\n",
    "    '#80FF00', '#DAFF00', '#FFFF00', '#FFF500', '#FFDA00', '#FFB000', '#FFA400',\n",
    "    '#FF4F00', '#FF2500', '#FF0A00', '#FF00FF'\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Visualization palette for u- and v-component of 10m wind\n",
    "visWind = {\n",
    "  'min': 0,\n",
    "  'max': 30,\n",
    "  'palette': [\n",
    "    '#FFFFFF', '#FFFF71', '#DEFF00', '#9EFF00', '#77B038', '#007E55', '#005F51',\n",
    "    '#004B51', '#013A7B', '#023AAD'\n",
    "  ]\n",
    "}\n",
    "\n",
    "# Visualization palette for pressure (surface pressure, mean sea level\n",
    "# pressure) - adjust min and max values for mslp to min:990 and max:1050\n",
    "visPressure = {\n",
    "  'min': 500,\n",
    "  'max': 1150,\n",
    "  'palette': [\n",
    "    '#01FFFF', '#058BFF', '#0600FF', '#DF00FF', '#FF00FF', '#FF8C00', '#FF8C00'\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map = geemap.Map(center = (-2.609097222, -60.20929722), zoom = 10)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add layer to map\n",
    "Map.addLayer(\n",
    "    era5_tp.filter(ee.Filter.date('2019-07-15')), visTp,\n",
    "    'Daily total precipitation sums')\n",
    "Map.addLayer(\n",
    "    era5_2d.filter(ee.Filter.date('2019-07-15')), vis2mt,\n",
    "    'Daily mean 2m dewpoint temperature')\n",
    "Map.addLayer(\n",
    "    era5_2mt.filter(ee.Filter.date('2019-07-15')), vis2mt,\n",
    "    'Daily mean 2m air temperature')\n",
    "Map.addLayer(\n",
    "    era5_u_wind_10m.filter(ee.Filter.date('2019-07-15')), visWind,\n",
    "    'Daily mean 10m u-component of wind')\n",
    "Map.addLayer(\n",
    "    era5_sp.filter(ee.Filter.date('2019-07-15')), visPressure,\n",
    "    'Daily mean surface pressure')\n",
    "\n",
    "#Map.setCenter(21.2, 22.2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tp_percentile_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total precipitation\n",
    "# get area statistics\n",
    "tp_mean_list = region_mean_ImageCollection(era5_tp)\n",
    "tp_median_list = region_median_ImageCollection(era5_tp)\n",
    "tp_stddev_list = region_stddev_ImageCollection(era5_tp)\n",
    "tp_percentile_list = region_percentiles_ImageCollection(era5_tp)\n",
    "\n",
    "# turn it into numpy array\n",
    "tp_mean = newList(tp_mean_list, 'total_precipitation')\n",
    "tp_median = newList(tp_median_list, 'total_precipitation')\n",
    "tp_stddev = newList(tp_stddev_list, 'total_precipitation')\n",
    "tp_percentile = p_list(tp_percentile_list, 'total_precipitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2m air temperature\n",
    "# get area statistics\n",
    "t2m_mean_list = region_mean_ImageCollection(era5_2mt)\n",
    "t2m_median_list = region_median_ImageCollection(era5_2mt)\n",
    "t2m_stddev_list = region_stddev_ImageCollection(era5_2mt)\n",
    "t2m_percentile_list = region_percentiles_ImageCollection(era5_2mt)\n",
    "\n",
    "# turn it into numpy array\n",
    "t2m_mean = newList(t2m_mean_list, 'mean_2m_air_temperature')\n",
    "t2m_median = newList(t2m_median_list, 'mean_2m_air_temperature')\n",
    "t2m_stddev = newList(t2m_stddev_list, 'mean_2m_air_temperature')\n",
    "t2m_percentile = p_list(t2m_percentile_list, 'mean_2m_air_temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5dates = ymdList(era5_tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mean and stddev to file\n",
    "site_era5 = pd.DataFrame()\n",
    "site_era5['dates'] = era5dates\n",
    "site_era5['precip_mean'] = tp_mean\n",
    "site_era5['precip_stddev'] = tp_stddev\n",
    "site_era5['t2m_mean'] = t2m_mean\n",
    "site_era5['t2_stddev'] = t2m_stddev\n",
    "\n",
    "filename = \"/data/6ru/%s_era5.daily\"%(sitename)\n",
    "site_era5.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ########################################\n",
    "## GLDAS 2.1\n",
    "# ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLDAS Net Longwave Radiation\n",
    "gldas21_net_longwave_radiation = (ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n",
    "                          .select('Lwnet_tavg')\n",
    "                          .filterBounds(fc)\n",
    "                          .filter(ee.Filter.date('2016-01-01', '2016-12-31')))\n",
    "\n",
    "# GLDAS Net Shortwave Radiation\n",
    "gldas21_net_shortwave_radiation = (ee.ImageCollection('NASA/GLDAS/V021/NOAH/G025/T3H')\n",
    "                          .select('Swnet_tavg')\n",
    "                          .filterBounds(fc)\n",
    "                          .filter(ee.Filter.date('2016-01-01', '2016-12-31')))\n",
    "\n",
    "#print(gldas21_net_longwave_radiation.size())\n",
    "#print(gldas21_net_shortwave_radiation.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3 hourly to daily time series -- take mean of values within the day\n",
    "#1-day step\n",
    "years = ee.List.sequence(2016, 2016)\n",
    "period = ee.List.sequence(1, 30, 1)\n",
    "\n",
    "\n",
    "def byYear(y):\n",
    "    y = ee.Number(y)\n",
    "    def dailymean(startDoy):\n",
    "        startDoy = ee.Number(startDoy)\n",
    "        return (gldas21_net_longwave_radiation\n",
    "                .filter(ee.Filter.calendarRange(y, y, 'year'))\n",
    "                .filter(ee.Filter.calendarRange(startDoy, startDoy, 'day_of_year'))\n",
    "                .median())\n",
    "    return period.map(dailymean)\n",
    "\n",
    "mapped_doy = years.map(byYear).flatten()\n",
    "gldas21_net_longwave_radiation = ee.ImageCollection.fromImages(mapped_doy)\n",
    "\n",
    "\n",
    "def byYear(y):\n",
    "    y = ee.Number(y)\n",
    "    def dailymean(startDoy):\n",
    "        startDoy = ee.Number(startDoy)\n",
    "        return (gldas21_net_shortwave_radiation\n",
    "                .filter(ee.Filter.calendarRange(y, y, 'year'))\n",
    "                .filter(ee.Filter.calendarRange(startDoy, startDoy, 'day_of_year'))\n",
    "                .median())\n",
    "    return period.map(dailymean)\n",
    "\n",
    "mapped_doy = years.map(byYear).flatten()\n",
    "gldas21_net_shortwave_radiation = ee.ImageCollection.fromImages(mapped_doy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net longwave radiation\n",
    "# get area statistics\n",
    "nlwr_mean_list = region_mean_ImageCollection(gldas21_net_longwave_radiation)\n",
    "nlwr_median_list = region_median_ImageCollection(gldas21_net_longwave_radiation)\n",
    "nlwr_stddev_list = region_stddev_ImageCollection(gldas21_net_longwave_radiation)\n",
    "nlwr_percentile_list = region_percentiles_ImageCollection(gldas21_net_longwave_radiation)\n",
    "\n",
    "# turn it into numpy array\n",
    "nlwr_mean = newList(nlwr_mean_list, 'Lwnet_tavg')\n",
    "nlwr_median = newList(nlwr_median_list, 'Lwnet_tavg')\n",
    "nlwr_stddev = newList(nlwr_stddev_list, 'Lwnet_tavg')\n",
    "nlwr_percentile = p_list(nlwr_percentile_list, 'Lwnet_tavg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net shortwave radiation\n",
    "# get area statistics\n",
    "nswr_mean_list = region_mean_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "nswr_median_list = region_median_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "nswr_stddev_list = region_stddev_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "nswr_percentile_list = region_percentiles_ImageCollection(gldas21_net_shortwave_radiation)\n",
    "\n",
    "# turn it into numpy array\n",
    "nswr_mean = newList(nswr_mean_list, 'Swnet_tavg')\n",
    "nswr_median = newList(nswr_median_list, 'Swnet_tavg')\n",
    "nswr_stddev = newList(nswr_stddev_list, 'Swnet_tavg')\n",
    "nswr_percentile = p_list(nswr_percentile_list, 'Swnet_tavg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export GLDAS2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mean and stddev to file\n",
    "site_gldas21 = pd.DataFrame()\n",
    "\n",
    "site_gldas21['nlwrad_mean'] = nlwr_mean\n",
    "site_gldas21['nlwrad_stddev'] = nlwr_stddev\n",
    "site_gldas21['nswrad_mean'] = nswr_mean\n",
    "site_gldas21['nswrad_stddev'] = nswr_stddev\n",
    "\n",
    "filename = \"/home/jbk/projects/climate/tropics/sentinel-2/data/gldas21/%s_gldas21.daily\"%(sitename)\n",
    "site_gldas21.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make few plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make lists with +/- SD\n",
    "plus_error = [x + y for x,y in zip(tp_mean, tp_stddev)]\n",
    "minus_error = [x - y for x,y in zip(tp_mean, tp_stddev)]\n",
    "\n",
    "plt.axes([2, 0, 2, 1])\n",
    "plt.grid(b = True, which = 'major', axis = 'x')\n",
    "plt.fill_between(icdates, plus_error, minus_error, color = \"grey\", alpha = .5, label = \"Standard Deviation\")\n",
    "plt.plot(icdates, tp_mean, label='tp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_stddev(var_mean, var_stddev, var_name):\n",
    "    #Make lists with +/- SD\n",
    "    icdates=np.array(list(range(0,30)))\n",
    "    plus_error = [x + y for x,y in zip(var_mean, var_stddev)]\n",
    "    minus_error = [x - y for x,y in zip(var_mean, var_stddev)]\n",
    "\n",
    "    plt.axes([2, 0, 2, 1])\n",
    "    plt.grid(b = True, which = 'major', axis = 'x')\n",
    "    plt.fill_between(icdates, plus_error, minus_error, color = \"grey\", alpha = .5, label = \"Standard Deviation\")\n",
    "    plt.plot(icdates, var_mean, label=var_name)\n",
    "    plt.legend(loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(tp_mean, tp_stddev, var_name=\"Total Precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(t2m_mean, t2m_stddev, var_name=\"2m Air Temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(nlwr_mean, nlwr_stddev, var_name=\"Net Long Wave Radiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_stddev(nlwr_mean, nlwr_stddev, var_name=\"Net Short Wave Radiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export mean and stddev to file\n",
    "edata = np.column_stack((icdates, tp_mean, tp_stddev, t2m_mean, t2m_stddev))\n",
    "site_era5 = pd.DataFrame()\n",
    "site_era5['dates'] = icdates\n",
    "site_era5['precip_mean'] = tp_mean\n",
    "site_era5['precip_stddev'] = tp_stddev\n",
    "site_era5['t2m_mean'] = t2m_mean\n",
    "site_era5['t2_stddev'] = t2m_stddev\n",
    "site_era5['nlwrad_mean'] = nlwr_mean\n",
    "site_era5['nlwrad_stddev'] = nlwr_stddev\n",
    "site_era5['nswrad_mean'] = nswr_mean\n",
    "site_era5['nswrad_stddev'] = nswr_stddev\n",
    "\n",
    "site_era5.to_csv('manaus_era5.daily', index=False)\n",
    "#site_era5.to_csv('atto_era5.daily', index=False)\n",
    "#site_era5.to_csv('corumba_era5.daily', index=False)\n",
    "#site_era5.to_csv('mato_era5.daily', index=False)\n",
    "#site_era5.to_csv('saop_era5.daily', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate variables for Growing Degree Days calculation \n",
    "start_date = ee.Date('2016-01-01', 'UTC')\n",
    "def maccum_byYear(y):\n",
    "    def maccum_byMonth(m):\n",
    "        return (ic\n",
    "                .filter(ee.Filter.calendarRange(y, y, 'year'))\n",
    "                .filter(ee.Filter.calendarRage(m, m, 'month'))\n",
    "                .\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = ee.Date('2016-01-01', 'UTC')\n",
    "new_date = start_date.advance(2, 'month')\n",
    "#print(start_date)\n",
    "print(start_date, new_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ee.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gldasdates = ymdList(gldas21_net_longwave_radiation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gldasdates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
